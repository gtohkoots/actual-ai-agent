# =============================
# Daily Snapshot Tool
# =============================
from __future__ import annotations

import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

from pydantic import BaseModel, Field

from langchain.tools import tool
from langchain.agents import AgentType, initialize_agent
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI

# --- project imports ---
from services import insights
from utils.db import get_transactions_in_date_range


# =============================
# Lightweight explicit state
# =============================
STATE = {
    "start_date": None,   # "YYYY-MM-DD"
    "end_date": None,     # "YYYY-MM-DD"
    # Preferences (can move to a config file later)
    "big_expense_threshold": 200.0,
    "top_n_categories": 5,
    "top_n_payees": 5,
}


def _current_week_range() -> tuple[str, str]:
    today = datetime.today().date()
    start = today - timedelta(days=today.weekday())
    end = start + timedelta(days=6)
    return start.isoformat(), end.isoformat()


# =============================
# Pydantic schemas for tools
# =============================
class TimeRange(BaseModel):
    start_date: Optional[str] = Field(None, description="YYYY-MM-DD")
    end_date: Optional[str] = Field(None, description="YYYY-MM-DD")


class SaveReportInput(BaseModel):
    markdown: str = Field(..., description="The report content in Markdown")
    tag: Optional[str] = Field(None, description="Optional filename tag, e.g. '2025-08-31'")


class DailySnapshotInput(BaseModel):
    date: Optional[str] = Field(None, description="å¿«ç…§æ—¥æœŸï¼ŒYYYY-MM-DDï¼Œç•™ç©ºåˆ™ä¸ºä»Šå¤©")


# =============================
# Tools
# =============================
@tool(args_schema=TimeRange, return_direct=False)
def update_time_window_tool(start_date: Optional[str] = None, end_date: Optional[str] = None) -> str:
    """æ›´æ–°å½“å‰åˆ†ææ—¶é—´åŒºé—´ã€‚å¿…é¡»ä½¿ç”¨ 'YYYY-MM-DD' æ ¼å¼ã€‚è‹¥æœªæä¾›åˆ™è®¾ç½®ä¸ºæœ¬å‘¨ï¼ˆå‘¨ä¸€åˆ°å‘¨æ—¥ï¼‰ã€‚è¿”å›å·²ç”Ÿæ•ˆçš„åŒºé—´ã€‚"""
    if not start_date or not end_date:
        start_date, end_date = _current_week_range()
    # basic validation
    try:
        datetime.strptime(start_date, "%Y-%m-%d"); datetime.strptime(end_date, "%Y-%m-%d")
    except Exception:
        return "æ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ 'YYYY-MM-DD'"
    STATE["start_date"], STATE["end_date"] = start_date, end_date
    return f"å·²è®¾ç½®æ—¶é—´åŒºé—´: {start_date} ~ {end_date}"


@tool(args_schema=TimeRange)
def get_weekly_data_tool(start_date: Optional[str] = None, end_date: Optional[str] = None) -> str:
    """è·å–æŸæ—¶é—´æ®µçš„å…¨éƒ¨äº¤æ˜“ï¼ˆJSON æ•°ç»„ï¼‰ã€‚åˆ—: date, amount(ç¾å…ƒ), payee, category, accountã€‚æœ€å¤šè¿”å›500è¡Œã€‚"""
    s = start_date or STATE.get("start_date")
    e = end_date or STATE.get("end_date")
    if not s or not e:
        return "æœªè®¾ç½®æ—¶é—´åŒºé—´ï¼Œè¯·å…ˆè°ƒç”¨ update_time_window_tool æˆ–ä¼ å…¥å‚æ•°"

    df = get_transactions_in_date_range(s, e, join_names=True, dollars=True)
    df = df[[c for c in ["date", "amount", "payee", "category", "account"] if c in df.columns]].sort_values("date")
    if len(df) > 500:
        df = df.tail(500)
    # ensure floats with 2 decimals for amount
    df["amount"] = df["amount"].astype(float).round(2)
    return df.to_json(orient="records", date_format="iso", force_ascii=False)


@tool(args_schema=TimeRange)
def get_week_rollups_tool(start_date: Optional[str] = None, end_date: Optional[str] = None) -> str:
    """è¿”å›è¯¥æ—¶é—´æ®µçš„å…³é”®æŒ‡æ ‡ä¸æ¦œå•(JSON)ï¼šæ€»æ”¶å…¥/æ€»æ”¯å‡º/å‡€ç°é‡‘æµã€Top åˆ†ç±»ã€Top payeesã€>$threshold å¤§é¢æ”¯å‡ºã€‚"""
    s = start_date or STATE.get("start_date")
    e = end_date or STATE.get("end_date")
    if not s or not e:
        return "æœªè®¾ç½®æ—¶é—´åŒºé—´ï¼Œè¯·å…ˆè°ƒç”¨ update_time_window_tool æˆ–ä¼ å…¥å‚æ•°"
    payload = insights.get_week_rollups(
        s,
        e,
        df=None,
        top_n_categories=STATE["top_n_categories"],
        top_n_payees=STATE["top_n_payees"],
        big_expense_threshold=STATE["big_expense_threshold"],
    )
    return json.dumps(payload, ensure_ascii=False)


@tool(args_schema=TimeRange)
def compare_to_last_week_tool(start_date: Optional[str] = None, end_date: Optional[str] = None) -> str:
    """è¿”å›è¯¥æ—¶é—´æ®µä¸ä¸Šå‘¨å¯¹æ¯”(JSON): æ”¶å…¥/æ”¯å‡º/å‡€ç°é‡‘æµå·®å€¼ä¸ç™¾åˆ†æ¯”ã€åˆ†ç±»å˜åŒ–Topåˆ—è¡¨ã€‚"""
    s = start_date or STATE.get("start_date")
    e = end_date or STATE.get("end_date")
    if not s or not e:
        return "æœªè®¾ç½®æ—¶é—´åŒºé—´ï¼Œè¯·å…ˆè°ƒç”¨ update_time_window_tool æˆ–ä¼ å…¥å‚æ•°"
    payload = insights.compare_week_over_week(s, e)
    return json.dumps(payload, ensure_ascii=False)


@tool(args_schema=SaveReportInput)
def save_weekly_report_tool(markdown: str, tag: Optional[str] = None) -> str:
    """å°†ç”Ÿæˆçš„ markdown æŠ¥å‘Šä¿å­˜åˆ° weekly_reports ç›®å½•ã€‚è¿”å›ä¿å­˜è·¯å¾„ã€‚"""
    ts = tag or datetime.now().strftime("%Y-%m-%d")
    p = Path("weekly_reports"); p.mkdir(exist_ok=True)
    path = p / f"weekly_report_{ts}.md"
    path.write_text(markdown)
    return str(path)


@tool(args_schema=DailySnapshotInput)
def save_daily_snapshot_tool(date: Optional[str] = None) -> str:
    """å°†æŒ‡å®šæ—¥æœŸï¼ˆæˆ–ä»Šå¤©ï¼‰çš„è´¢åŠ¡åˆ†æå¿«ç…§ä¿å­˜ä¸º JSON æ–‡ä»¶ï¼Œå­˜å‚¨åœ¨ daily_snapshots ç›®å½•ã€‚è¿”å›ä¿å­˜è·¯å¾„ã€‚"""
    d = date or datetime.now().strftime("%Y-%m-%d")
    s, e = d, d
    df = get_transactions_in_date_range(s, e, join_names=True, dollars=True)
    if df.empty:
        return f"{d} æ— äº¤æ˜“æ•°æ®ï¼Œæœªç”Ÿæˆå¿«ç…§ã€‚"
    # è·å–æ€»æ”¶å…¥ã€æ€»æ”¯å‡ºã€åˆ†ç±»ç»Ÿè®¡
    total_income = float(df[df["amount"] > 0]["amount"].sum())
    total_expense = float(df[df["amount"] < 0]["amount"].sum()) * -1  # å–æ­£å€¼
    # åˆ†ç±»ç»Ÿè®¡ï¼ŒåŒºåˆ†æ”¶å…¥å’Œæ”¯å‡º
    categories = {"income": {}, "expense": {}}
    if "category_name" in df.columns:
        cat_group = df.groupby(["category_name"])["amount"].sum()
        for cat, val in cat_group.items():
            if val > 0:
                categories["income"].update({cat: float(round(val, 2))})
            elif val < 0:
                categories["expense"].update({cat: float(round(-val, 2))})
    # notes: æ£€æŸ¥æ˜¯å¦æœ‰å¤§é¢æ”¯å‡º
    big_expense = df[(df["amount"] < 0) & (df["amount"].abs() > STATE["big_expense_threshold"])]
    notes = "ä»Šæ—¥æœ‰å¤§é¢æ”¯å‡º : {}".format(big_expense) if not big_expense.empty else ""
    snapshot = {
        "date": d,
        "total_income": round(total_income, 2),
        "total_expense": round(total_expense, 2),
        "categories": categories,
        "notes": notes
    }
    snapshot_dir = Path("daily_snapshots")
    snapshot_dir.mkdir(exist_ok=True)
    file_path = snapshot_dir / f"{d}.json"
    with open(file_path, "w", encoding="utf-8") as f:
        json.dump(snapshot, f, ensure_ascii=False, indent=2)
    return f"å·²ä¿å­˜ {d} å¿«ç…§: {file_path}"

# =============================
# LLM + Agent
# =============================
TOOLS = [
    update_time_window_tool,
    get_weekly_data_tool,
    get_week_rollups_tool,
    compare_to_last_week_tool,
    save_weekly_report_tool,
    save_daily_snapshot_tool,
]

SYSTEM_MESSAGE = (
    "ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡ä¸ªäººè´¢åŠ¡åˆ†æåŠ©æ‰‹ã€‚ä½ å¯ä»¥æ›´æ–°åˆ†ææ—¶é—´åŒºé—´ã€è¯»å–äº¤æ˜“æ•°æ®å¹¶ç”Ÿæˆæ·±å…¥çš„å‘¨æŠ¥ã€‚\n\n"
    "è¾“å‡ºè§„èŒƒï¼š\n"
    "- é‡‘é¢ä¸€å¾‹ä»¥ç¾å…ƒæ˜¾ç¤ºï¼Œå¹¶åœ¨æ•°å­—å‰æ·»åŠ  $ï¼Œä¿ç•™ä¸¤ä½å°æ•°ï¼ˆå¦‚ $1,234.56ï¼‰ã€‚\n"
    "- ç”Ÿæˆå‘¨æŠ¥æ—¶ï¼Œè¯·æŒ‰ä»¥ä¸‹æµç¨‹ï¼š\n"
    "  1) è‹¥æ—¶é—´ä¸æ˜ç¡®ï¼Œè°ƒç”¨ update_time_window_tool è®¾ç½®ä¸ºæœ¬å‘¨ï¼ˆå‘¨ä¸€è‡³å‘¨æ—¥ï¼‰ï¼›\n"
    "  2) è°ƒç”¨ get_week_rollups_tool è·å– Facts JSONï¼›å¿…è¦æ—¶è°ƒç”¨ compare_to_last_week_tool è·å– WoW å¯¹æ¯”ï¼›\n"
    "  3) åŸºäº Facts å…ˆåˆ—å‡ºä¸€ä¸ª JSON Facts å°èŠ‚ï¼Œç„¶åå†å†™ Markdown æŠ¥å‘Šï¼ˆåˆ†ç« èŠ‚ï¼šæ”¶å…¥ã€æ”¯å‡ºã€å‡€ç°é‡‘æµã€Top åˆ†ç±»/Payeesã€WoW å¯¹æ¯”ã€å¼‚å¸¸/å¤§é¢ã€å»ºè®®ä¸é¢„ç®—ï¼‰ï¼›\n"
    "  4) å¦‚ç”¨æˆ·è¦æ±‚ä¿å­˜æˆ–å½’æ¡£ï¼Œè°ƒç”¨ save_weekly_report_tool(markdown)ã€‚\n"
    "æˆ‘ä»¬é»˜è®¤ä»Šå¹´æ˜¯2025å¹´, æ‰€æœ‰åˆ†æã€æŠ¥å‘Šã€é»˜è®¤æ—¶é—´éƒ½ä»¥æ­¤ä¸ºå‡†ã€‚\n"
)


def main() -> None:
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    agent = initialize_agent(
        tools=TOOLS,
        llm=llm,
        agent=AgentType.OPENAI_FUNCTIONS,
        verbose=True,
        memory=memory,
        agent_kwargs={"system_message": SYSTEM_MESSAGE},
    )

    print("\nğŸ’¼ è´¢åŠ¡åˆ†æåŠ©æ‰‹å·²å¯åŠ¨ã€‚ç¤ºä¾‹é—®é¢˜ï¼š")
    print("- ç”Ÿæˆä¸€ä»½æœ¬å‘¨çš„è¯¦ç»†å‘¨æŠ¥å¹¶ä¿å­˜")
    print("- å°†æ—¶é—´è®¾ä¸º 2025-08-01 åˆ° 2025-08-07ï¼Œç„¶åç»™æˆ‘è¯¦ç»†æŠ¥å‘Š")
    print("- è¿™å‘¨å’Œä¸Šå‘¨ç›¸æ¯”ï¼Œæ”¯å‡ºå˜åŒ–å¦‚ä½•ï¼Ÿ")
    print("è¾“å…¥ exit/quit é€€å‡º\n")

    while True:
        query = input("ä½ ï¼š").strip()
        if query.lower() in {"exit", "quit"}:
            print("å†è§"); break
        try:
            resp = agent.run(query)
            print("\nåŠ©æ‰‹ï¼š", resp, "\n")
        except Exception as e:
            print(f"é”™è¯¯: {e}\n")


if __name__ == "__main__":
    main()
